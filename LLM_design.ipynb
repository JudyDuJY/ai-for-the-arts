{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed1eafc9",
   "metadata": {},
   "source": [
    "# Large Language Models\n",
    "## Voices Between the Lines\n",
    "### Introduction\n",
    "In this mini-design project, I proposed a conceptual application using Large Language Models (LLMs) to support learners in understanding cultural and historical texts, as well as overlooked or marginalised voices in archival materials. In this course, I primarily encountered LLMs through Microsoft Copilot, which greatly aided in learning Python and understanding code. This led me to consider whether similar AI tools could be applied to fields beyond programming, such as culture, history, and education.\n",
    "\n",
    "Many historical texts, museum exhibit descriptions, or archival materials are often written from a mainstream or institutional perspective. From a student's perspective, these texts are not only linguistically difficult but also frequently overlook the viewpoints of certain groups. Therefore, the design focus of this application is not to have AI provide the \"correct answer,\" but rather to assist users in understanding and reflection, especially when dealing with complex or controversial cultural content.\n",
    "\n",
    "### Application Overview\n",
    "This application, titled \"Voices Between the Lines,\" is an interactive learning tool centered around a large language model (LLM) that allows users to explore cultural or historical texts more deeply. Unlike typical AI tools that only summarise content, this application aims to help users understand the original text in simpler language, identify dominant voices and perspectives within the text, and consider which voices might be overlooked or marginalised.\n",
    "\n",
    "Users can upload or select historical texts (such as colonial-era documents, museum descriptions, and library archive summaries). The system will then generate simplified descriptions, supplementary interpretations from multiple perspectives, and narratives written from different viewpoints (e.g., colonists, minorities, women, labourers).\n",
    "\n",
    "This design emphasises conversational interaction between humans and AI, rather than a one-way output of answers from the AI. This application is primarily designed for students, museum visitors, and the general public, aiming to enable them to read cultural materials more critically.\n",
    "\n",
    "\n",
    "### Intended Users and Context\n",
    "The target users of this application include:   \n",
    "\n",
    "Students studying history, cultural studies, or digital humanities   \n",
    "\n",
    "Visitors interacting with digital archives in libraries or museums   \n",
    "\n",
    "Learners with limited language skills or background knowledge    \n",
    "\n",
    "The primary use cases are educational or cultural institutions, such as classrooms, libraries, or archives, where \"guided learning\" and reflection are more important than providing quick answers.    \n",
    "\n",
    "### Human–AI Interaction\n",
    "1. User Input\n",
    "Users first paste a short text, such as descriptions of museum exhibits, excerpts from historical archives, or historical explanations from textbooks. Next, users can choose how they want the AI ​​to assist, such as: \"Please explain in simpler language,\" \"Point out any biases or assumptions in this text,\" or \"Try rewriting it from a different perspective (e.g., local residents, marginalised groups).\" This design aims to allow users to actively decide the AI's role, rather than passively accepting the result.\n",
    "\n",
    "2. The Role of Large Language Models\n",
    "In this application, large language models analyse the text's linguistic structure and historical context, identify potential power perspectives and biases (such as colonial narratives), generate possible interpretations using training data, and then produce different interpretations based on prompts.\n",
    "\n",
    "This design reflects that LLM generates responses based on probability and language patterns. The interface clearly indicates that these responses are AI-generated interpretations, not \"knowing the truth.”\n",
    "\n",
    "3. Output and User Reflection\n",
    "The system may provide the following outputs:    \n",
    "A plain-language explanation of the original text.    \n",
    "A brief explanation pointing out potential biases in the language, supplemented with cultural or historical context.    \n",
    "An alternative perspective written in a speculative or reflective tone.     \n",
    "After reading, users can compare the AI ​​response with the original text, determine whether they agree with the interpretation, evaluate the helpfulness of the response, and then ask follow-up questions to explore other possible perspectives, such as requesting further clarification or comparing different viewpoints.     \n",
    "This design aims to promote active thinking, rather than passive reading.\n",
    "\n",
    "\n",
    "###  Understanding How Large Language Models Work\n",
    "This design reflects my understanding of large language models.   \n",
    "LLMs are not databases; they are trained on a large amount of text data and generate text based on language patterns found in the training data. Responses are based on probability and language patterns, not true understanding. Furthermore, the quality of the responses depends on the diversity of the training data and the design of the prompts, so the model may reproduce biases from the training data.   \n",
    "Therefore, in this application, LLMs are positioned as tools to aid thinking, not as authoritative sources or teachers.    \n",
    "\n",
    "###  The Value of Learning, Cultural Engagement, and Inclusivity\n",
    "Cultural and historical texts can be daunting for many beginners. By simplifying language, providing step-by-step explanations of complex historical texts, and allowing for repeated questioning, this application lowers the barrier to understanding, helping students learn with greater confidence. Simultaneously, the application encourages users to think about how cultural narratives are constructed, allowing them to explore culture in a \"conversational\" manner, paying attention to power relations in historical writing, and actively interacting with the text rather than simply receiving information. This echoes the AI-driven cultural application case studies discussed in the classroom. A core objective of this design is to make users aware of \"who is being represented\" or \"who is being ignored.\" In this way, the application increases visibility to marginalised groups, highlights the issues of inclusivity and colonisation, and can support discussions on decolonisation and pluralistic representation within cultural institutions.\n",
    "\n",
    "###  Model and Platform Selection (Design Choice)\n",
    "From a design perspective, I believe this application is best suited for small to medium-sized or local large language models (such as the Ollama or Llama series). Deployment can be done in local or private environments (such as Ollama).     \n",
    "Reasons: Firstly, it reduces user data leakage, improving privacy. Secondly, it is suitable for educational and cultural institutions, while also addressing concerns about the lack of transparency of large cloud platforms.\n",
    "\n",
    "###  Critical Reflection on Social and Cultural Influences  \n",
    "While this application aims to enhance inclusivity, risks remain. Because LLM is trained on existing texts, the \"alternative voices\" it generates may still reflect mainstream views and even unintentionally reinforce stereotypes. The \"alternative voices\" generated by AI may still be speculative rather than based on actual historical experience. Furthermore, users may over-rely on AI's interpretations, potentially weakening their critical reading skills of original sources and thus overlooking their importance.     \n",
    "Therefore, this design emphasizes AI as an aid and guide, not as formal conclusions. Users are encouraged to return to the original texts, read them, and reflect upon them.     \n",
    "This aligns with the course's discussion on transparency, explainability, and responsible AI use.\n",
    "\n",
    "###  Conclusion\n",
    "This mini-design (Voices Between the Lines) demonstrates a responsible and creative way to apply large-scale language models (LLMs) in cultural learning contexts, combining technological capabilities with cultural sensitivity. By emphasizing human-computer interaction, reflection, and inclusivity, this application illustrates how LLMs can assist learning and cultural engagement, fostering an understanding of historical and cultural diversity without replacing human judgment. The process of designing this application also helped me to think more deeply about the social and cultural impact of AI, rather than simply viewing it as a technological tool."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
